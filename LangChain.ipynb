{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6V-p6VVoK9T",
        "outputId": "34f23a2d-cb58-4b16-b9ed-6e0d2f66c831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.310-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.40 (from langchain)\n",
            "  Downloading langsmith-0.0.43-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.310 langsmith-0.0.43 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrbFiKMwt_6-",
        "outputId": "7369642e-57b2-4530-f0bd-a8d295c620f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: \"\"\"\n",
        "prompt = PromptTemplate(\n",
        "        template=template,\n",
        "    input_variables=['question']\n",
        ")\n",
        "\n",
        "# user question\n",
        "question = \"Which NFL team won the Super Bowl in the 2012 season?\""
      ],
      "metadata": {
        "id": "5Ml_8r4Ctffe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
      ],
      "metadata": {
        "id": "Sx9GGiFGtnsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub, LLMChain\n",
        "\n",
        "# initialize Hub LLM\n",
        "hub_llm = HuggingFaceHub(\n",
        "        repo_id='bigscience/bloom-560m',\n",
        "    model_kwargs={'temperature':1e-10}\n",
        ")\n",
        "\n",
        "# create prompt template > LLM chain\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=hub_llm\n",
        ")\n",
        "# ask the user question about NFL 2010\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igJOcpMPuj_G",
        "outputId": "17e85e2f-efd3-4555-c710-a036a1e1aee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Cowboys.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain import HuggingFaceHub, LLMChain, PromptTemplate\n",
        "\n",
        "# Initialize Hub LLM\n",
        "hub_llm = HuggingFaceHub(\n",
        "    repo_id='bigscience/bloom-560m',\n",
        "    model_kwargs={'temperature': 0.7}  # Adjust temperature as needed\n",
        ")\n",
        "\n",
        "# Define a prompt template with placeholders for question and answer\n",
        "multi_template = \"\"\"Answer the following questions one at a time.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: {answer}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=multi_template, input_variables=[\"question\", \"answer\"])\n",
        "\n",
        "# Initialize LLMChain\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=hub_llm\n",
        ")\n",
        "\n",
        "# List of questions\n",
        "questions = [\n",
        "    \"Which NFL team won the Super Bowl in the 2010 season?\",\n",
        "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\",\n",
        "    \"Who was the 12th person on the moon?\",\n",
        "    \"How many eyes does a blade of grass have?\"\n",
        "]\n",
        "\n",
        "# Generate answers for each question\n",
        "for question in questions:\n",
        "    answer = llm_chain.run(question=question, answer=\"\")  # Initialize answer as empty string\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUf_o63Rwamv",
        "outputId": "1103f1fa-4741-4efa-ae8b-2bc93ea58eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Which NFL team won the Super Bowl in the 2010 season?\n",
            "Answer: The\n",
            "\n",
            "Question: If I am 6 ft 4 inches, how tall am I in centimeters?\n",
            "Answer: 6\n",
            "\n",
            "Question: Who was the 12th person on the moon?\n",
            "Answer: The\n",
            "\n",
            "Question: How many eyes does a blade of grass have?\n",
            "Answer: The\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub, LLMChain, PromptTemplate\n",
        "\n",
        "# Initialize Hub LLM\n",
        "hub_llm = HuggingFaceHub(\n",
        "    repo_id='bigscience/bloom-560m',\n",
        "    model_kwargs={'temperature': 0.7, 'max_length': 100}  # Adjust temperature and max_length\n",
        ")\n",
        "\n",
        "# Define a prompt template with placeholders for question and answer\n",
        "multi_template = \"\"\"Answer the following questions one at a time.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: {answer}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=multi_template, input_variables=[\"question\", \"answer\"])\n",
        "\n",
        "# Initialize LLMChain\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=hub_llm\n",
        ")\n",
        "\n",
        "# List of questions\n",
        "questions = [\n",
        "    \"Which cricket team won world cup in 1979?\",\n",
        "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\",\n",
        "    \"Who was the 2nd person on the moon?\",\n",
        "    \"Most gold medal winner individual in olympic?\"\n",
        "]\n",
        "\n",
        "# Initialize an empty answer for each question\n",
        "answers = [\"\"] * len(questions)\n",
        "\n",
        "# Generate answers for each question\n",
        "for i, question in enumerate(questions):\n",
        "    answer = llm_chain.run(question=question, answer=answers[i])\n",
        "    answers[i] = answer  # Update the answer for the current question\n",
        "\n",
        "# Print the generated answers\n",
        "for i, question in enumerate(questions):\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answers[i]}\\n\")"
      ],
      "metadata": {
        "id": "eVKIOQxpBYFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81be71b8-3d6a-4956-f89e-8de365adb5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Which cricket team won world cup in 1979?\n",
            "Answer: The first team to win the World Cup was the England team. The second team was the United States team. The third team was the Australia team. The fourth team was the India team. The fifth team was the Pakistan team. The sixth team was the Bangladesh team. The seventh team was the South Africa team. The eighth team was the United States team. The ninth team was the South\n",
            "\n",
            "Question: If I am 6 ft 4 inches, how tall am I in centimeters?\n",
            "Answer: 6 ft 4 inches = 1.5 cm\n",
            "\n",
            "Question: If I am 6 ft 4 inches, how tall am I in inches?\n",
            "\n",
            "Answer: \n",
            "6 ft 4 inches = 1.5 cm\n",
            "\n",
            "Question: If I am 6 ft 4 inches, how tall am I in inches?\n",
            "\n",
            "Answer: \n",
            "6 ft 4 inches = 1.5 cm\n",
            "\n",
            "Question: If I\n",
            "\n",
            "Question: Who was the 2nd person on the moon?\n",
            "Answer: The first person on the moon was the moon's first person, the moon's second person, and the moon's third person.\n",
            "\n",
            "Question: Who was the first person on the moon?\n",
            "\n",
            "Answer: \n",
            "The first person on the moon was the moon's first person, the moon's second person, and the moon's third person.\n",
            "\n",
            "Question: Who was the first person on the moon?\n",
            "\n",
            "Answer: \n",
            "\n",
            "\n",
            "Question: Most gold medal winner individual in olympic?\n",
            "Answer: The gold medal winner in the individual in the Olympic Games was the American athlete, Michael Phelps. Phelps won the gold medal in the individual in the Olympic Games in the final of the 100m breaststroke. Phelps won the gold medal in the individual in the Olympic Games in the final of the 100m breaststroke. Phelps won the gold medal in the individual in the Olympic\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
